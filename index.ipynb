{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Tensorflow and Keras"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "T8EQBfbRRV7w"}, "source": ["## Modeling\n", "\n", "Let's review some modeling concepts we've used to date with [this quick exercise](https://forms.gle/yrPxUp2Xj4R9FeyEA)\n"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Hko6Q989RV7w"}, "source": ["We do this to remind ourselves that the basic components of good modeling practice, and even the methods themselves, are _the same_ with Neural Nets as that are with _sklearn_ or _statsmodels_.\n", "\n", "The above exercise uses only one train-test split, but is still usefule.  We will be using train, validation, test in this notebook, for good practice."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "Xv_Ypg88RV7x"}, "source": ["## Objectives:\n", "- Compare pros and cons of Keras vs TensorFlow\n", "- hands on practice coding a neural network"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wait a second, what is that warning? \n", "`Using TensorFlow backend.`"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<img align =left src=\"img/keras.png\"><br>\n", "### Keras is an API\n", "\n", "Coded in Python, that can be layered on top of many different back-end processing systems.\n", "\n", "![kerasback](img/keras_tf_theano.png)\n", "\n", "While each of these systems has their own coding methods, Keras abstracts from that in streamlined pythonic manner we are used to seeing in other python modeling libraries.\n", "\n", "Keras development is backed primarily by Google, and the Keras API comes packaged in TensorFlow as tf.keras. Additionally, Microsoft maintains the CNTK Keras backend. Amazon AWS is maintaining the Keras fork with MXNet support. Other contributing companies include NVIDIA, Uber, and Apple (with CoreML)."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "EdZDyJfARV8l"}, "source": ["## Wait, what's TensorFlow?\n"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "mFZYNoYRRV8l"}, "source": ["## Let's start with tensors"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "mIZD7WFvRV8m"}, "source": ["## Tensors are multidimensional matricies\n", "\n", "![tensor](img/tensors.png)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "OUblayDlRV8n"}, "source": ["### TensorFlow manages the flow of matrix math\n", "\n", "That makes neural network processing possible.\n", "\n", "![cat](img/cat-tensors.gif)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For our numbers dataset, our tensors from the sklearn dataset were originally tensors of the shape 8x8, i.e.64 pictures.  Remember, that was with black and white images.\n", "\n", "For image processing, we are often dealing with color."]}, {"cell_type": "markdown", "metadata": {}, "source": ["What do the dimensions of our image above represent?"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Even with tensors of higher **rank**"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A matrix with rows and columns only, like the black and white numbers, are **rank 2**.\n", "\n", "A matrix with a third dimension, like the color pictures above, are **rank 3**.\n", "\n", "When we flatten an image by stacking the rows in a column, we are decreasing the rank. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["When we unrow a column, we increase its rank."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Wait, what tool am I even using, what's Keras?\n", "## More levers and buttons\n", "\n", "Coding directly in **Tensorflow** allows you to tweak more parameters to optimize performance. The **Keras** wrapper makes the code more accessible for developers prototyping models.\n", "\n", "![levers](img/levers.jpeg)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "nTxfhoqMRV8o"}, "source": ["### Keras, an API with an intentional UX\n", "\n", "- Deliberately design end-to-end user workflows\n", "- Reduce cognitive load for your users\n", "- Provide helpful feedback to your users\n", "\n", "[full article here](https://blog.keras.io/user-experience-design-for-apis.html)<br>\n", "[full list of why to use Keras](https://keras.io/why-use-keras/)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "qTNbwNeRRV8p"}, "source": ["### A few comparisons\n", "\n", "While you **can leverage both**, here are a few comparisons.\n", "\n", "| Comparison | Keras | Tensorflow|\n", "|------------|-------|-----------|\n", "| **Level of API** | high-level API | High and low-level APIs |\n", "| **Speed** |  can *seem* slower |  is a bit faster |\n", "| **Language architecture** | simple architecture, more readable and concise | straight tensorflow is a bit mroe complex |\n", "| **Debugging** | less frequent need to debug | difficult to debug |\n", "| **Datasets** | usually used for small datasets | high performance models and large datasets that require fast execution|\n", "\n", "This is also a _**non-issue**_ - as you can leverage tensorflow commands within keras and vice versa. If Keras ever seems slower, it's because the developer's time is more expensive than the GPUs. Keras is designed with the developer in mind. \n", "\n", "\n", "[reference link](https://www.edureka.co/blog/keras-vs-tensorflow-vs-pytorch/)"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "TwkD4T2eRV7y"}, "source": ["### Think, Pair, Share Challenge:\n", "\n", "<img src=\"https://images.pexels.com/photos/1350560/pexels-photo-1350560.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\" alt=\"diabetes\" style =\"text-align:center;width:250px;float:none\" ></br>"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's begin implementing our neural net with the UCI digit dataset we imported from sklearn yesterday."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's continue where we left off with our numbers dataset."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will start with a binary classification, and predict whether the number will be even or odd."]}, {"cell_type": "markdown", "metadata": {}, "source": ["In pairs, proceed through the following three parts. "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Part 1:\n", "Questions to answer:\n", "- How many input variables are there in this dataset? \n", "- What does the range of values (0-16) represent in our feature set?\n", "- What does a 1 mean in our target class?\n", "- If we use a neural net to predict this, what loss function do we use?\n", "***"]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "#### Part 2:\n", "What if you wanted to create a NN with hidden layers to predict even numbers with:\n", "- 12 nodes in the first hidden layer\n", "- 8 nodes in the second hidden layer\n", "- relu on the first two activations\n", "- sigmoid on the last one\n", "\n", "Answer the following questions:\n", "- How many nodes in the input layer?\n", "- How many nodes in the output layer?\n", "- Will the output layer produce an integer or a float?\n", "***"]}, {"cell_type": "markdown", "metadata": {}, "source": ["***\n", "\n", "#### Part 3:\n", "Knowing that you want:\n", "- batch size of 10\n", "- 50 epochs\n", "- to use `rmsprop` as your optimizer\n", "- and all the numbers you defined above...\n", "\n", "**Fill out the code below with the correct specifications, but don't run it yet**"]}, {"cell_type": "code", "execution_count": 172, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Epoch 1/50\n", "1797/1797 [==============================] - 2s 1ms/step - loss: 0.5585 - acc: 0.7446\n", "Epoch 2/50\n", "1797/1797 [==============================] - 0s 203us/step - loss: 0.2448 - acc: 0.9009\n", "Epoch 3/50\n", "1797/1797 [==============================] - 0s 198us/step - loss: 0.1640 - acc: 0.9349\n", "Epoch 4/50\n", "1797/1797 [==============================] - 0s 177us/step - loss: 0.1305 - acc: 0.9482\n", "Epoch 5/50\n", "1797/1797 [==============================] - 0s 177us/step - loss: 0.1068 - acc: 0.9638\n", "Epoch 6/50\n", "1797/1797 [==============================] - 0s 167us/step - loss: 0.0902 - acc: 0.9705\n", "Epoch 7/50\n", "1797/1797 [==============================] - 0s 159us/step - loss: 0.0793 - acc: 0.9716\n", "Epoch 8/50\n", "1797/1797 [==============================] - 0s 190us/step - loss: 0.0715 - acc: 0.9766\n", "Epoch 9/50\n", "1797/1797 [==============================] - 0s 179us/step - loss: 0.0621 - acc: 0.9789\n", "Epoch 10/50\n", "1797/1797 [==============================] - 0s 160us/step - loss: 0.0564 - acc: 0.9794\n", "Epoch 11/50\n", "1797/1797 [==============================] - 0s 157us/step - loss: 0.0516 - acc: 0.9822\n", "Epoch 12/50\n", "1797/1797 [==============================] - 0s 196us/step - loss: 0.0475 - acc: 0.9822\n", "Epoch 13/50\n", "1797/1797 [==============================] - 0s 168us/step - loss: 0.0417 - acc: 0.9861\n", "Epoch 14/50\n", "1797/1797 [==============================] - 0s 168us/step - loss: 0.0402 - acc: 0.9855\n", "Epoch 15/50\n", "1797/1797 [==============================] - 0s 203us/step - loss: 0.0351 - acc: 0.9894\n", "Epoch 16/50\n", "1797/1797 [==============================] - 0s 164us/step - loss: 0.0324 - acc: 0.9878\n", "Epoch 17/50\n", "1797/1797 [==============================] - 0s 175us/step - loss: 0.0292 - acc: 0.9905\n", "Epoch 18/50\n", "1797/1797 [==============================] - 0s 181us/step - loss: 0.0276 - acc: 0.9894\n", "Epoch 19/50\n", "1797/1797 [==============================] - 0s 164us/step - loss: 0.0248 - acc: 0.9905\n", "Epoch 20/50\n", "1797/1797 [==============================] - 0s 186us/step - loss: 0.0239 - acc: 0.9939\n", "Epoch 21/50\n", "1797/1797 [==============================] - 0s 179us/step - loss: 0.0211 - acc: 0.9933\n", "Epoch 22/50\n", "1797/1797 [==============================] - 0s 180us/step - loss: 0.0206 - acc: 0.9922\n", "Epoch 23/50\n", "1797/1797 [==============================] - 0s 164us/step - loss: 0.0193 - acc: 0.9922\n", "Epoch 24/50\n", "1797/1797 [==============================] - 0s 175us/step - loss: 0.0188 - acc: 0.9939\n", "Epoch 25/50\n", "1797/1797 [==============================] - 0s 172us/step - loss: 0.0142 - acc: 0.9972\n", "Epoch 26/50\n", "1797/1797 [==============================] - 0s 164us/step - loss: 0.0139 - acc: 0.9950\n", "Epoch 27/50\n", "1797/1797 [==============================] - 0s 160us/step - loss: 0.0117 - acc: 0.9967\n", "Epoch 28/50\n", "1797/1797 [==============================] - 0s 190us/step - loss: 0.0116 - acc: 0.9961\n", "Epoch 29/50\n", "1797/1797 [==============================] - 0s 186us/step - loss: 0.0106 - acc: 0.9950\n", "Epoch 30/50\n", "1797/1797 [==============================] - 0s 187us/step - loss: 0.0092 - acc: 0.9972\n", "Epoch 31/50\n", "1797/1797 [==============================] - 0s 193us/step - loss: 0.0120 - acc: 0.9955\n", "Epoch 32/50\n", "1797/1797 [==============================] - 0s 206us/step - loss: 0.0094 - acc: 0.9967\n", "Epoch 33/50\n", "1797/1797 [==============================] - 0s 218us/step - loss: 0.0082 - acc: 0.9983\n", "Epoch 34/50\n", "1797/1797 [==============================] - 0s 189us/step - loss: 0.0058 - acc: 0.9978\n", "Epoch 35/50\n", "1797/1797 [==============================] - 0s 176us/step - loss: 0.0081 - acc: 0.9972\n", "Epoch 36/50\n", "1797/1797 [==============================] - 0s 195us/step - loss: 0.0067 - acc: 0.9972\n", "Epoch 37/50\n", "1797/1797 [==============================] - 0s 181us/step - loss: 0.0066 - acc: 0.9983\n", "Epoch 38/50\n", "1797/1797 [==============================] - 0s 187us/step - loss: 0.0052 - acc: 0.9983\n", "Epoch 39/50\n", "1797/1797 [==============================] - 0s 203us/step - loss: 0.0035 - acc: 0.9989\n", "Epoch 40/50\n", "1797/1797 [==============================] - 0s 181us/step - loss: 0.0064 - acc: 0.9978\n", "Epoch 41/50\n", "1797/1797 [==============================] - 0s 178us/step - loss: 0.0043 - acc: 0.9972\n", "Epoch 42/50\n", "1797/1797 [==============================] - 0s 202us/step - loss: 0.0041 - acc: 0.9989\n", "Epoch 43/50\n", "1797/1797 [==============================] - 0s 199us/step - loss: 0.0037 - acc: 0.9994\n", "Epoch 44/50\n", "1797/1797 [==============================] - 0s 194us/step - loss: 0.0044 - acc: 0.9989\n", "Epoch 45/50\n", "1797/1797 [==============================] - 0s 222us/step - loss: 0.0041 - acc: 0.9989\n", "Epoch 46/50\n", "1797/1797 [==============================] - 0s 185us/step - loss: 0.0056 - acc: 0.9983\n", "Epoch 47/50\n", "1797/1797 [==============================] - 0s 191us/step - loss: 0.0027 - acc: 0.9994\n", "Epoch 48/50\n", "1797/1797 [==============================] - 0s 201us/step - loss: 0.0031 - acc: 0.9994\n", "Epoch 49/50\n", "1797/1797 [==============================] - 0s 167us/step - loss: 0.0023 - acc: 0.9994\n", "Epoch 50/50\n", "1797/1797 [==============================] - 0s 173us/step - loss: 0.0034 - acc: 0.9994\n"]}, {"data": {"text/plain": ["<keras.callbacks.History at 0x1a60c6cda0>"]}, "execution_count": 172, "metadata": {}, "output_type": "execute_result"}], "source": ["\n", "model = Sequential()\n", "model.add(Dense(12, activation='relu', input_dim=64,))\n", "model.add(Dense(8 ,  activation='relu' ))\n", "model.add(Dense(1 , activation = 'sigmoid' ))\n", "\n", "model.compile(optimizer='rmsprop' ,\n", "              loss='binary_crossentropy'  ,\n", "              metrics=['accuracy'])\n", "model.fit(X, y_binary, epochs=50, batch_size= 10 )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Things to know:\n", "- the data and labels in `fit()` need to be numpy arrays, not pandas dfs. Else it won't work.\n", "- Scaling your data will have a large impact on your model.   \n", "  > For our traditional input features, we would use a scalar object.  For images, as long as the minimum value is 0, we can simply divide through by the maximum pixel intensity.\n", "\n", "![gif](https://media0.giphy.com/media/3og0IMJcSI8p6hYQXS/giphy.gif)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Getting data ready for modeling\n", "**Tasks**:\n", "\n", "- use train_test_split to create X_train, y_train, X_test, and y_test\n", "- Split training data into train and validation sets.\n", "- Scale the pixel intensity to a value between 0 and 1.\n", "- Scale the pixel intensity to a value between 0 and 1."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Scaling data for neural networks is very important, whether it be for image processing or prediction problems like we've seen in past projects and lessons.  \n", "\n", "Scaling our input variables will help speed up our neural network [see 4.3](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n", "\n", "Since our minimum intensity is 0, we can normalize the inputs by dividing each value by the max value (16). "]}, {"cell_type": "code", "execution_count": 174, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, random_state=42, test_size=.2)\n", "X_t, X_val, y_t, y_val = train_test_split(X_train, y_train, random_state=42, test_size=.2)\n", "X_t, X_val, X_test = X_t/16, X_val/16, X_test/16\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now that our data is ready, let's load in keras"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's start working through the different choices we can make in our network."]}, {"cell_type": "markdown", "metadata": {}, "source": ["For activation, let's start with the familiar sigmoid function, and see how it performs."]}, {"cell_type": "markdown", "metadata": {}, "source": ["If we look at our loss, it is still decreasing. That is a signal that our model is still learning. If our model is still learning, we can allow it to get better by increasing the number of epochs."]}, {"cell_type": "markdown", "metadata": {}, "source": ["It still looks like our model has not converged.  The loss is still decreasing, and the accuracy is still increasing.  We could continue increasing the epochs, but that will be time consuming.  \n", "\n", "We could try decreasing the batch size. Let's set the batch size to 1.  This is true stochastic gradient descent.  The parameters are updated after each sample is passed into the model.\n", "\n", "SGD with a small batch size takes longer to run through an epoch, but will take less epochs to improve."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Comparing our 50 epoch version with a 500 batch size and a 10 epoch version with a 1 example batch size, we see that by 10 epochs, the latter has achieved 90% accuracy by the final epoch, while our 23 batch size is just about 70%.  However, with the 1 example batch, each epoch took a lot longer."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Still, even though the 2nd model reached a higher accuracy and lower loss, it looks like it still has not stopped learning. The slope of the loss is getting smaller, but it has not leveled out completely."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's get a bit more modern, and apply a relu activation function in our layers."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We are reaching a high accuracy, but still looks like our model has not converged. If we increased our number of epochs, we would be looking at a long wait."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have been implementing the vanilla version of gradient descent.  Remember, SGD updates the parameters uniformly across the board.  Let's try out an optimizer used more often these days."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now our accuracy is really improving, and it looks like our learning may be leveling out."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Since Adam and relu are relatively faster than SGD and sigmoid, we can add more epochs, and more layers without the training time getting unwieldy."]}, {"cell_type": "markdown", "metadata": {}, "source": ["No it looks like we're getting somewhere.\n", "\n", "For comparison, look at how much more quickly Adam learns than SGD."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have been looking only at our training set. Let's add in our validation set to the picture."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Consider that we still see our loss decreasing and our accuracy increasing.  We try to add more complexity to our model by adding more layers."]}, {"cell_type": "markdown", "metadata": {}, "source": ["We see that our model is overfit.  Just like in our previous models, after a certain amount of learning, the loss on the validation set starts increasing."]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Regularization"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n", "Does regularization make sense in the context of neural networks? <br/>\n", "\n", "Yes! We still have all of the salient ingredients: a loss function, overfitting vs. underfitting, and coefficients (weights) that could get too large.\n", "\n", "But there are now a few different flavors besides L1 and L2 regularization. (Note that L1 regularization is not common in the context of  neural networks.)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Early Stopping"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's return to the original problem: predicting 0 through 9"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Keras comes with all sorts of handy tools, including ways to streamline train test split from folders on your desktop. You will definitely find this useful. Learn will lead the way.\n", "\n", "You don't have this dog vs. cat dataset on your computer, but that is ok. \n", "\n", "The code below shows how we process that data with Keras. It also shows that a basic neural net does not perform well on the dataset.  Tomorrow, we will explore better tools for image processing."]}], "metadata": {"celltoolbar": "Slideshow", "colab": {"collapsed_sections": [], "name": "intro-to-keras.ipynb", "provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.9"}}, "nbformat": 4, "nbformat_minor": 4}